{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science\n",
    "## Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Student Name: Gina Holden\n",
    "\n",
    "    Student Netid: gh1407\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Case study (5 Points)\n",
    "- Read [this article](http://www.nytimes.com/2012/02/19/magazine/shopping-habits.html) in the New York Times.\n",
    "- Use what we've learned in class and from the book to describe how one could set Target's problem up as a predictive modeling problem, such that they could have gotten the results that they did.  Formulate your solution as a proposed plan using our data science terminology.  Include all the aspects of the formulation that you see as relevant to solving the problem.  Be precise but concise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Set formation\n",
    "The article mentions Target has access to a baby shower registry. Since we are sure these people are pregnant and furthermore we know what trimester they are in, we can use the past purchase data associated with their guest id to create a labeled dataset. The primary key for each observation would be the guest id, and the features could be certain product purchases. For example, \"has bought unscented lotion in past week\" or \"has bought extra large bag of cotton balls in past week.\" The values for the columns could be booleans. Alternatively, you could count the number of purchases so the columns could be \"number of purchases of unscented lotion\". The target value for each observation could be boolean: \"is pregnant\" or you could codify the trimesters and pregnant vs not pregnant into values like 0-4 and try to predict not only if they are pregnant but what trimester they are in. \n",
    "Once you have all your positive cases from the registry and past purchase log, we need to find out the negative observations, women who are not pregnant, to train the model against. There is not a definite way to determine if a woman is not pregnant, but we can take a guess. You could take all the women (with a similar demographic as your positive data set, ie no elderly women or children) who have not bought anything remotely baby related within the past six months. Then you analyze their past spending and calculate the same feature vector you collected for the pregnant women. \n",
    "Once you have all that data, you could hold out some of it from training to test with later. \n",
    "#### Model Selection\n",
    "Since we have only learned about binary regression in class, I would simplify the problem to just predict whether the person is pregnant or not. Depending on the outcome of initial data exploration, logistic regression may be a good choice. you will have to explore the variables and make sure there are no variables that are highly correlated with eachother, and maybe throw out any variables that don't show significant correlation with the target. \n",
    "#### Model fitting\n",
    "Is easy once you have the features set up you just use LogisticRegression from scikit learn. before you feed your data into the algorithm you could split out the test data using train_test_split method. once you have that, it's easy to score with the .score function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Exploring data in the command line (4 Points - 1 each)\n",
    "For this part we will be using the data file located in `\"advertising_events.csv\"`. This file consists of records that pertain to some online advertising events on a given day. There are 4 comma separated columns in this order: `userid`, `timestamp`, `domain`, and `action`. These fields are of type `int`, `int`, `string`, and `int` respectively. Answer the following questions using Linux/Unix bash commands. All questions can be answered in one line (sometimes, with pipes)! Some questions will have many possible solutions. Don't forget that in IPython notebooks you must prefix all bash commands with an exclamation point, i.e. `\"!command arguments\"`.\n",
    "\n",
    "[Hints: You can experiment with whatever you want in the notebook and then delete things to construct your answer later.  You can also use ssh to use the actual bash shell in your terminal and then just paste your answers here. Recall that once you enter the \"!\" then filename completion should work. Also, these are standard data exploration commands that are quick and easy to use in a terminal or in the notebook. We don't cover command line operations formally in this class, but these are worth learning (and thus are part of the HW). Be resourceful. Use whatever online cheat sheets or Stackoverflow to answer the question.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. How many records (lines) are in this file (look up wc)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10341 advertising_events.csv\r\n"
     ]
    }
   ],
   "source": [
    "! wc -l advertising_events.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. How many unique users are in this file? (hint: consider the 'cut' command and use pipe operator '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     732\r\n"
     ]
    }
   ],
   "source": [
    "! cut -d \",\" -f 1 advertising_events.csv  | sort -u | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Rank all domains by the number of visits they received in descending order. (hint: consider the 'cut', 'uniq' and 'sort' commands and the pipe operator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3114 google.com\r\n",
      "2092 facebook.com\r\n",
      "1036 youtube.com\r\n",
      "1034 yahoo.com\r\n",
      "1022 baidu.com\r\n",
      " 513 wikipedia.org\r\n",
      " 511 amazon.com\r\n",
      " 382 qq.com\r\n",
      " 321 twitter.com\r\n",
      " 316 taobao.com\r\n"
     ]
    }
   ],
   "source": [
    "! cut -d \",\" -f 3 advertising_events.csv  | sort | uniq -c  | sort -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. List all records for the user with user id 37. (hint: this can be done using 'grep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37,648061658,google.com,0\r\n",
      "37,642479972,google.com,2\r\n",
      "37,644493341,facebook.com,2\r\n",
      "37,654941318,facebook.com,1\r\n",
      "37,649979874,baidu.com,1\r\n",
      "37,653061949,yahoo.com,1\r\n",
      "37,655020469,google.com,3\r\n",
      "37,640878012,amazon.com,0\r\n",
      "37,659864136,youtube.com,1\r\n",
      "37,640361378,yahoo.com,1\r\n",
      "37,653862134,facebook.com,0\r\n",
      "37,648828970,youtube.com,0\r\n"
     ]
    }
   ],
   "source": [
    "! awk -F, '$1 == 37' advertising_events.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Dealing with data Pythonically (16 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might find these packages useful. You may import any others you want!\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Load the data set `\"ads_dataset.tsv\"` into a Python Pandas data frame called `ads`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbuyer</th>\n",
       "      <th>buy_freq</th>\n",
       "      <th>visit_freq</th>\n",
       "      <th>buy_interval</th>\n",
       "      <th>sv_interval</th>\n",
       "      <th>expected_time_buy</th>\n",
       "      <th>expected_time_visit</th>\n",
       "      <th>last_buy</th>\n",
       "      <th>last_visit</th>\n",
       "      <th>multiple_buy</th>\n",
       "      <th>multiple_visit</th>\n",
       "      <th>uniq_urls</th>\n",
       "      <th>num_checkins</th>\n",
       "      <th>y_buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>2130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>1100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>539</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-101.149300</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>362</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54579</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.979170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.621240</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>2080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54580</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.916713</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54581</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54582</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54583</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>401</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54584 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       isbuyer  buy_freq  visit_freq  buy_interval  sv_interval  \\\n",
       "0            0       NaN           1           0.0     0.000000   \n",
       "1            0       NaN           1           0.0     0.000000   \n",
       "2            0       NaN           1           0.0     0.000000   \n",
       "3            0       NaN           1           0.0     0.000000   \n",
       "4            0       NaN           2           0.0     0.500000   \n",
       "...        ...       ...         ...           ...          ...   \n",
       "54579        0       NaN           3           0.0    30.979170   \n",
       "54580        0       NaN           2           0.0     1.041667   \n",
       "54581        0       NaN           1           0.0     0.000000   \n",
       "54582        0       NaN           1           0.0     0.000000   \n",
       "54583        0       NaN           1           0.0     0.000000   \n",
       "\n",
       "       expected_time_buy  expected_time_visit  last_buy  last_visit  \\\n",
       "0                    0.0             0.000000       106         106   \n",
       "1                    0.0             0.000000        72          72   \n",
       "2                    0.0             0.000000         5           5   \n",
       "3                    0.0             0.000000         6           6   \n",
       "4                    0.0          -101.149300       101         101   \n",
       "...                  ...                  ...       ...         ...   \n",
       "54579                0.0            12.621240         8           8   \n",
       "54580                0.0            -0.916713         1           1   \n",
       "54581                0.0             0.000000        20          20   \n",
       "54582                0.0             0.000000       180         180   \n",
       "54583                0.0             0.000000       185         185   \n",
       "\n",
       "       multiple_buy  multiple_visit  uniq_urls  num_checkins  y_buy  \n",
       "0                 0               0        169          2130      0  \n",
       "1                 0               0        154          1100      0  \n",
       "2                 0               0          4            12      0  \n",
       "3                 0               0        150           539      0  \n",
       "4                 0               1        103           362      0  \n",
       "...             ...             ...        ...           ...    ...  \n",
       "54579             0               1        168          2080      0  \n",
       "54580             0               1          1            15      0  \n",
       "54581             0               0        132           556      0  \n",
       "54582             0               0         71           400      0  \n",
       "54583             0               0         77           401      0  \n",
       "\n",
       "[54584 rows x 14 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads = pd.read_csv(\"ads_dataset.tsv\", sep='\\t', header=(0))\n",
    "ads = ads.reset_index(drop=True)\n",
    "ads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Write a Python function called `getDfSummary()` that does the following:\n",
    "- Takes as input a data frame\n",
    "- For each variable in the data frame calculates the following features:\n",
    "  - `number_nan` to count the number of missing not-a-number values\n",
    "  - Ignoring missing, NA, and Null values:\n",
    "    - `number_distinct` to count the number of distinct values a variable can take on\n",
    "    - `mean`, `max`, `min`, `std` (standard deviation), and `25%`, `50%`, `75%` to correspond to the appropriate percentiles\n",
    "- All of these new features should be loaded in a new data frame. Each row of the data frame should be a variable from the input data frame, and the columns should be the new summary features.\n",
    "- Returns this new data frame containing all of the summary information\n",
    "\n",
    "Hint: The pandas `describe()` [(manual page)](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html) method returns a useful series of values that can be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isbuyer                    0\n",
      "buy_freq               52257\n",
      "visit_freq                 0\n",
      "buy_interval               0\n",
      "sv_interval                0\n",
      "expected_time_buy          0\n",
      "expected_time_visit        0\n",
      "last_buy                   0\n",
      "last_visit                 0\n",
      "multiple_buy               0\n",
      "multiple_visit             0\n",
      "uniq_urls                  0\n",
      "num_checkins               0\n",
      "y_buy                      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>number_nan</th>\n",
       "      <th>number_distinct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>isbuyer</td>\n",
       "      <td>54584.0</td>\n",
       "      <td>0.042632</td>\n",
       "      <td>0.202027</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>buy_freq</td>\n",
       "      <td>2327.0</td>\n",
       "      <td>1.240653</td>\n",
       "      <td>0.782228</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>52257.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>visit_freq</td>\n",
       "      <td>54584.0</td>\n",
       "      <td>1.852777</td>\n",
       "      <td>2.921820</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>84.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>buy_interval</td>\n",
       "      <td>54584.0</td>\n",
       "      <td>0.210008</td>\n",
       "      <td>3.922016</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>174.62500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sv_interval</td>\n",
       "      <td>54584.0</td>\n",
       "      <td>5.825610</td>\n",
       "      <td>17.595442</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>184.91670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>expected_time_buy</td>\n",
       "      <td>54584.0</td>\n",
       "      <td>-0.198040</td>\n",
       "      <td>4.997792</td>\n",
       "      <td>-181.9238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.28571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>expected_time_visit</td>\n",
       "      <td>54584.0</td>\n",
       "      <td>-10.210786</td>\n",
       "      <td>31.879722</td>\n",
       "      <td>-187.6156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.40192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>last_buy</td>\n",
       "      <td>54584.0</td>\n",
       "      <td>64.729335</td>\n",
       "      <td>53.476658</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>188.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>last_visit</td>\n",
       "      <td>54584.0</td>\n",
       "      <td>64.729335</td>\n",
       "      <td>53.476658</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>188.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>multiple_buy</td>\n",
       "      <td>54584.0</td>\n",
       "      <td>0.006357</td>\n",
       "      <td>0.079479</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>multiple_visit</td>\n",
       "      <td>54584.0</td>\n",
       "      <td>0.277444</td>\n",
       "      <td>0.447742</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>uniq_urls</td>\n",
       "      <td>54584.0</td>\n",
       "      <td>86.569343</td>\n",
       "      <td>61.969765</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>206.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_checkins</td>\n",
       "      <td>54584.0</td>\n",
       "      <td>720.657592</td>\n",
       "      <td>1275.727306</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>127.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>802.000000</td>\n",
       "      <td>37091.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>y_buy</td>\n",
       "      <td>54584.0</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>0.067924</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count        mean          std       min    25%    50%  \\\n",
       "isbuyer              54584.0    0.042632     0.202027    0.0000    0.0    0.0   \n",
       "buy_freq              2327.0    1.240653     0.782228    1.0000    1.0    1.0   \n",
       "visit_freq           54584.0    1.852777     2.921820    0.0000    1.0    1.0   \n",
       "buy_interval         54584.0    0.210008     3.922016    0.0000    0.0    0.0   \n",
       "sv_interval          54584.0    5.825610    17.595442    0.0000    0.0    0.0   \n",
       "expected_time_buy    54584.0   -0.198040     4.997792 -181.9238    0.0    0.0   \n",
       "expected_time_visit  54584.0  -10.210786    31.879722 -187.6156    0.0    0.0   \n",
       "last_buy             54584.0   64.729335    53.476658    0.0000   18.0   51.0   \n",
       "last_visit           54584.0   64.729335    53.476658    0.0000   18.0   51.0   \n",
       "multiple_buy         54584.0    0.006357     0.079479    0.0000    0.0    0.0   \n",
       "multiple_visit       54584.0    0.277444     0.447742    0.0000    0.0    0.0   \n",
       "uniq_urls            54584.0   86.569343    61.969765   -1.0000   30.0   75.0   \n",
       "num_checkins         54584.0  720.657592  1275.727306    1.0000  127.0  319.0   \n",
       "y_buy                54584.0    0.004635     0.067924    0.0000    0.0    0.0   \n",
       "\n",
       "                            75%          max  number_nan  number_distinct  \n",
       "isbuyer                0.000000      1.00000         0.0                2  \n",
       "buy_freq               1.000000     15.00000     52257.0               10  \n",
       "visit_freq             2.000000     84.00000         0.0               64  \n",
       "buy_interval           0.000000    174.62500         0.0              295  \n",
       "sv_interval            0.104167    184.91670         0.0             5886  \n",
       "expected_time_buy      0.000000     84.28571         0.0              348  \n",
       "expected_time_visit    0.000000     91.40192         0.0            15135  \n",
       "last_buy             105.000000    188.00000         0.0              189  \n",
       "last_visit           105.000000    188.00000         0.0              189  \n",
       "multiple_buy           0.000000      1.00000         0.0                2  \n",
       "multiple_visit         1.000000      1.00000         0.0                2  \n",
       "uniq_urls            155.000000    206.00000         0.0              207  \n",
       "num_checkins         802.000000  37091.00000         0.0             4628  \n",
       "y_buy                  0.000000      1.00000         0.0                2  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getDfSummary(input_data):\n",
    "    num_uniq = input_data.nunique().values\n",
    "    num_rows = len(input_data)\n",
    "    print(input_data.isna().sum())\n",
    "    output_data = input_data.describe().T\n",
    "    output_data['number_nan'] = num_rows - output_data['count'] \n",
    "    output_data['number_distinct'] = num_uniq.T\n",
    "    return output_data\n",
    "getDfSummary(ads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. How long does it take for your `getDfSummary()` function to work on your `ads` data frame? Show us the results below.\n",
    "\n",
    "Hint: `%timeit getDfSummary(ads)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.499078564000001"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timeit\n",
    "timeit.timeit(lambda: getDfSummary(ads), number=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Using the results returned from `getDfSummary()`, which fields, if any, contain missing `NaN` values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "buy_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. For the fields with missing values, does it look like the data is missing at random? Are there any other fields that correlate perfectly, or predict that the data is missing? If missing, what should the data value be?\n",
    "\n",
    "Hint: create another data frame that has just the records with a missing value. Get a summary of this data frame using `getDfSummary()` and compare the differences. Do some feature distributions change dramatically?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "buy_freq is Nan whenever isbuyer column is false. This intuitively makes sense because if they are not a buyer, how do you quantify buyer frequency? If you do want to fill in a value, you could say zero because they never buy anything. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'getDfSummary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e5fd5d3856f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgetDfSummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'getDfSummary' is not defined"
     ]
    }
   ],
   "source": [
    "getDfSummary(ads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Which variables are binary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "isbuyer, multiple_buy, uniq_urls, y_buy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
