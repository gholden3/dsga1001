{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "data = pd.read_csv(\"seekers_iso_pop_econ_fips_gdelt_NEXT_YEAR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create current_population feature\n",
    "curr_pop_list = []\n",
    "for index, row in data.iterrows():\n",
    "    curr_year = str(int(row.Year))\n",
    "    curr_pop = row[curr_year]\n",
    "    curr_pop_list.append(curr_pop)\n",
    "data['current_population']=curr_pop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3757, 101)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2983, 101)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove N/A's in Gdelt fields and current_population (these are mismatched countries, bad records anyways)\n",
    "print(data.shape)\n",
    "data = data.dropna(subset=['QuadClass','NuMentions','current_population'])\n",
    "\n",
    "# Remove N/A's in economic data (hopefully we'll fill some of these)\n",
    "data = data.dropna(subset=['Unemployment Rate',\n",
    "                           'GDP Per Capita',\n",
    "                           'Life expectancy',])\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create y vector, 2000-2017\n",
    "years = np.arange(2000,2018)\n",
    "y = data.loc[data.Year.isin(years),'applied_next_year']\n",
    "\n",
    "# Create X feature matrix, including only the columns that we want to predict on in feature_list\n",
    "feature_list = [\n",
    "    'Applied during year',\n",
    "    'current_population',\n",
    "    'Unemployment Rate',\n",
    "    'GDP Per Capita',\n",
    "    'Life expectancy',\n",
    "    'GoldsteinScale',\n",
    "    'NuMentions',\n",
    "    'AvgTone',\n",
    "    'QuadClass',\n",
    "]\n",
    "X = data.loc[data.Year.isin(years),feature_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for columns with N/A's and count the N/A's\n",
    "for col in X:\n",
    "    if X[col].isna().any():\n",
    "        print(col,X[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling!\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "\n",
    "# Normalize X and y\n",
    "# Note: I'm normalizing (setting mean to 0) not standardizing (setting variance to 1)\n",
    "transformer = Normalizer().fit(X)\n",
    "X_norm = transformer.transform(X)\n",
    "y_norm = y / y.mean()\n",
    "\n",
    "#Train_test_split, post-normalizing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y_norm, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) \n",
      "r^2:  0.19927576965942828 \n",
      "\n",
      "ElasticNetCV(alphas=None, copy_X=True, cv=10, eps=0.001, fit_intercept=True,\n",
      "             l1_ratio=0.5, max_iter=1000, n_alphas=100, n_jobs=None,\n",
      "             normalize=False, positive=False, precompute='auto',\n",
      "             random_state=None, selection='cyclic', tol=0.0001, verbose=0) \n",
      "r^2:  0.018190136104514698 \n",
      "\n",
      "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      presort=False, random_state=None, splitter='best') \n",
      "r^2:  0.23945760374437974 \n",
      "\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                      n_jobs=None, oob_score=False, random_state=None,\n",
      "                      verbose=0, warm_start=False) \n",
      "r^2:  0.5034169924572591 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/python-virtual-environments/data/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Function for trying out models\n",
    "def test_reg(reg,X_train, X_test, y_train, y_test,return_reg=False):\n",
    "    '''test_reg takes a regressor object and the 4 data sets, trains the regressor, makes predictions\n",
    "    on the test set, and prints an r^2 score.  Returns trained regressor if return_reg=True.'''\n",
    "    reg.fit(X_train,y_train)\n",
    "    preds = reg.predict(X_test)\n",
    "    print(reg,\"\\nr^2: \",r2_score(y_test,preds),\"\\n\")\n",
    "    if return_reg:\n",
    "        return reg\n",
    "\n",
    "# Instantiate the regressors\n",
    "LR_reg = linear_model.LinearRegression()\n",
    "EN_reg = linear_model.ElasticNetCV(cv=10)\n",
    "DT_reg = tree.DecisionTreeRegressor()\n",
    "RF_reg = ensemble.RandomForestRegressor()\n",
    "\n",
    "# Train and test all models with default settings\n",
    "for model in [LR_reg,EN_reg,DT_reg,RF_reg]:\n",
    "    test_reg(model,X_train, X_test, y_train, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied during year: 0.37\n",
      "current_population: 0.066\n",
      "Unemployment Rate: 0.058\n",
      "GDP Per Capita: 0.15\n",
      "Life expectancy: 0.3\n",
      "GoldsteinScale: 0.0013\n",
      "NuMentions: 0.018\n",
      "AvgTone: 0.033\n",
      "QuadClass: 0.0021\n"
     ]
    }
   ],
   "source": [
    "# Random Forest provides feature_importance...not rock solid, but useful for some context\n",
    "RF_reg.fit(X_train,y_train)\n",
    "\n",
    "for name,imp in zip(X.columns,RF_reg.feature_importances_):\n",
    "    print(\"{}: {:2.2}\".format(name,imp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
